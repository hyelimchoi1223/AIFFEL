{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recorded-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-species",
   "metadata": {},
   "source": [
    "# 데이터 압축 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "middle-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 압출 푸는 소스\n",
    "def unzip_file(root_path,foldername):\n",
    "    path = root_path+foldername\n",
    "    zip_file_names = [fn for fn in os.listdir(path) if fn.endswith('zip')]\n",
    "    print(zip_file_names)\n",
    "    count = 0\n",
    "    for zip_name in zip_file_names:\n",
    "        with zipfile.ZipFile(path+'/'+zip_name) as myzip:            \n",
    "            image_list = myzip.infolist()\n",
    "            for i, image in enumerate(image_list):\n",
    "                image.filename = f'{foldername}_{i+count}'\n",
    "                myzip.extract(image, path=root_path+\"extracted/\"+foldername)\n",
    "            count += len(image_list)\n",
    "            print(f'count{count}')\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "interior-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n",
      "['rock.zip', 'rocks_complete.zip', 'rock(1).zip', 'rock(3).zip', 'rock(2).zip']\n",
      "count100\n",
      "count1205\n",
      "count1305\n",
      "count1405\n",
      "count1505\n",
      "paper\n",
      "['papers_complete.zip', 'paper(2).zip', 'paper.zip', 'paper(1).zip', 'paper(3).zip']\n",
      "count1108\n",
      "count1208\n",
      "count1308\n",
      "count1408\n",
      "count1508\n",
      "scissor\n",
      "['scissor(2).zip', 'scissor.zip', 'scissors.zip', 'scissors_complete.zip', 'scissor(1).zip']\n",
      "count100\n",
      "count200\n",
      "count300\n",
      "count1294\n",
      "count1394\n"
     ]
    }
   ],
   "source": [
    "path = os.getenv('HOME')+'/aiffel/rock_scissor_paper_data/'\n",
    "hand_type = ['rock', 'paper', 'scissor']\n",
    "for foldername in hand_type:\n",
    "    print(foldername)\n",
    "    unzip_file(path,foldername)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-oklahoma",
   "metadata": {},
   "source": [
    "## 파일 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "usual-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getenv('HOME')+'/aiffel/rock_scissor_paper_data/'\n",
    "extracted_path = root_path + \"extracted/\"\n",
    "test_path = root_path + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-punishment",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-advancement",
   "metadata": {},
   "source": [
    "## 사이즈 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "agricultural-number",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(path+'extracted/rock/rock_0')\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hawaiian-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img_path):\n",
    "    images=glob.glob(img_path+\"/\"+\"*\")  \n",
    "    print(f\"{len(images)} will be resized\")\n",
    "    \n",
    "    target_size = (28,28)\n",
    "    for img in images:\n",
    "        old_image = Image.open(img)\n",
    "        new_image = old_image.resize(target_size, Image.ANTIALIAS)\n",
    "        new_image.save(img, \"JPEG\")\n",
    "        \n",
    "    print(f\"{len(images)} image resized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "industrial-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n",
      "1505 will be resized\n",
      "1505 image resized\n",
      "paper\n",
      "1508 will be resized\n",
      "1508 image resized\n",
      "scissor\n",
      "1394 will be resized\n",
      "1394 image resized\n"
     ]
    }
   ],
   "source": [
    "for foldername in os.listdir(extracted_path):\n",
    "    print(foldername)\n",
    "    resize_image(extracted_path+foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "different-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(extracted_path+'rock/rock_0')\n",
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-guatemala",
   "metadata": {},
   "source": [
    "## 가위, 바위, 보 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "applied-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 이미지 load\n",
    "Args:\n",
    "    img_root_path: 이미지 루트 경로\n",
    "    number_of_data: 로드할 데이터 개수\n",
    "Returns:\n",
    "    이미지 데이터, 해당 이미지의 라벨\n",
    "\"\"\"\n",
    "def load_data(img_root_path, number_of_data = 300):\n",
    "    \n",
    "        \"\"\" 원하는 타입의 이미지 데이터를 원하는 만큼 랜덤하게 뽑아내는 generator\n",
    "        Args:\n",
    "            path: 이미지 가져올 위치\n",
    "            hand_type: 분류 id -> {0:'scissor', 1:'rock', 2:'paper'}\n",
    "            count_data: 랜덤하게 뽑을 개수\n",
    "        Yield:\n",
    "            이미지 데이터를 int32 타입의 ndarray로 반환\n",
    "        \"\"\"\n",
    "        def get_image_generator(path, hand_type, count_data):\n",
    "            _path = path+hand_type+'/*'\n",
    "            result = np.array([])\n",
    "            rng = np.random.default_rng()\n",
    "            test = rng.choice(np.array(glob.glob(_path)), count_data, replace=False)\n",
    "            for file in test:\n",
    "                img = np.array(Image.open(file),dtype=np.int32)  \n",
    "                yield img\n",
    "    \n",
    "    \n",
    "        img_size=  28\n",
    "        color=3\n",
    "        # container 생성\n",
    "        imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size,img_size,color)\n",
    "        labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "        # 가위 = 0, 바위 = 1, 보 = 2    \n",
    "        count = 0\n",
    "        # number_of_data가 3의 배수가 아니여서 쓰레기 값이 들어가는 것을 막기 위해서 나머지만큼 클래스 순서대로 채운다.\n",
    "        quot, remainder = divmod(number_of_data, 3)\n",
    "        hand_type = {0:'scissor', 1:'rock', 2:'paper'}\n",
    "        for idx, _type in hand_type.items():\n",
    "            # 나머지와 동일한 type의 개수를 나머지만큼 더한다.\n",
    "            if idx == remainder:\n",
    "                _quot = quot+remainder\n",
    "            else:\n",
    "                _quot = quot\n",
    "                \n",
    "            for img in get_image_generator(img_root_path, _type, _quot):\n",
    "                imgs[count,:,:,:] = img\n",
    "                labels[count] = idx\n",
    "                count += 1\n",
    "            \n",
    "        return imgs, labels\n",
    "        \n",
    "        \n",
    "\"\"\" 테스트 이미지 load\n",
    "Args:\n",
    "    number_of_data: 로드할 데이터 개수\n",
    "Returns:\n",
    "    이미지 데이터, 해당 이미지의 라벨\n",
    "\"\"\"        \n",
    "def load_test_data(number_of_data = 300):\n",
    "    _path = test_path\n",
    "    return load_data(_path, number_of_data)\n",
    "\n",
    "\"\"\" 훈련 이미지 load\n",
    "Args:\n",
    "    number_of_data: 로드할 데이터 개수\n",
    "Returns:\n",
    "    이미지 데이터, 해당 이미지의 라벨\n",
    "\"\"\" \n",
    "def load_train_data(number_of_data = 300):\n",
    "    _path = extracted_path\n",
    "    return load_data(_path, number_of_data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-circumstances",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "collaborative-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 이미지 증강 레이어 생성 함수\n",
    "Returns:\n",
    "    모델\n",
    "\"\"\" \n",
    "def make_augmentaion():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.experimental.preprocessing.RandomRotation(0.1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "educated-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 이미지 딥러닝 네트워크 생성 함수\n",
    "Args:\n",
    "    n_conv_1 = 1번째 합성곱층 하이퍼파라미터\n",
    "    n_conv_2 = 2번째 합성곱층 하이퍼파라미터\n",
    "    n_conv_3 = 3번째 합성곱층 하이퍼파라미터\n",
    "    n_dense = Dense 층 하이퍼파라미터\n",
    "Returns:\n",
    "    모델\n",
    "\"\"\" \n",
    "def make_model(n_conv_1 = 16, n_conv_2 = 32, n_conv_3=32, n_dense = 32):\n",
    "    model = keras.models.Sequential()\n",
    "    # 입력부\n",
    "    model.add(keras.layers.Conv2D(n_conv_1,(3,3), activation='relu', input_shape=(28,28,3), strides=1))\n",
    "    model.add(keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(make_augmentaion())\n",
    "    model.add(keras.layers.Conv2D(n_conv_2, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(n_conv_3, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    # 출력부\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-weight",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "legitimate-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "sequential_61 (Sequential)   (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,491\n",
      "Trainable params: 15,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 1.1041 - accuracy: 0.3313\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0981 - accuracy: 0.3312\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0961 - accuracy: 0.3666\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.3826\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0876 - accuracy: 0.3873\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0617 - accuracy: 0.4330\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.4747\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9802 - accuracy: 0.5238\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9408 - accuracy: 0.5573\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8771 - accuracy: 0.6146\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8422 - accuracy: 0.6223\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7864 - accuracy: 0.6547\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.6535\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.6664\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.7243\n",
      "32/32 - 0s - loss: 0.6016 - accuracy: 0.7680\n",
      "0.6016152501106262 0.7680000066757202\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.6960\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7158 - accuracy: 0.6870\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.7010\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.7240\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.7130\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.7170\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7450\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7520\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.7440\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7380\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7630\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7850\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7870\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7760\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7760\n",
      "32/32 - 0s - loss: 0.4160 - accuracy: 0.8360\n",
      "0.4160364270210266 0.8360000252723694\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7900\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8110\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.8020\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7980\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8140\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8180\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7920\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8180\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8340\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8530\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8440\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8420\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8580\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8660\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8400\n",
      "32/32 - 0s - loss: 0.3076 - accuracy: 0.8750\n",
      "0.30761638283729553 0.875\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8290\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8230\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8150\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8150\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.8100\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8400\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8390\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8460\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8290\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8190\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8570\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8640\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8600\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8330\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8790\n",
      "32/32 - 0s - loss: 0.3595 - accuracy: 0.8520\n",
      "0.3594665229320526 0.8519999980926514\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8600\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8770\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8660\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8680\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8820\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8810\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8820\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8760\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8840\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8690\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8930\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8990\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9120\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9060\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8880\n",
      "32/32 - 0s - loss: 0.1880 - accuracy: 0.9270\n",
      "0.18802893161773682 0.9269999861717224\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "for _ in range(5):\n",
    "    x_train, y_train = load_train_data(1000)\n",
    "    # 정규화\n",
    "    x_train_norm = x_train/255.0\n",
    "    model.fit(x_train_norm, y_train, epochs=15)\n",
    "    test_loss, test_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
    "    print(test_loss, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-adjustment",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eleven-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 load\n",
    "x_test, y_test = load_test_data()\n",
    "# 정규화\n",
    "x_test_norm = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "confident-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.8913 - accuracy: 0.7233\n",
      "1.8912900686264038 0.7233333587646484\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(test_loss, test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
