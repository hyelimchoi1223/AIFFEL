{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-spouse",
   "metadata": {},
   "source": [
    "# 순환 신경망 (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-flush",
   "metadata": {},
   "source": [
    "rnn : 딥러닝에 있어 기본적인 시퀀스 모델    \n",
    "**활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서 다시 은닉층 노드의 입력으로 낸다.**    \n",
    "\n",
    "* cell : 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할. 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수행하므로 **메모리 셀**, **RNN 셀**이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-helping",
   "metadata": {},
   "source": [
    "참고 : https://wikidocs.net/22886"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-arbitration",
   "metadata": {},
   "source": [
    "단어 사전을 만들기 위해서 일정한 기준으로 쪼개는데 그것을 **토큰화(Tokenize)** 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-ethiopia",
   "metadata": {},
   "source": [
    "순수하게 단어만 토큰화를 하기 위해서 사전에 작업해야 하는 것이 있다.    \n",
    "1. 문장부호 없애기 -> 문장부호까지 포함해서 토큰화를 하기 때문에\n",
    "2. 대소문자 통일하기 -> Name과 name를 다른 문자로 받아들여 토큰화 하기 때문에\n",
    "3. 특수문자 없애기 -> 특수문자로 분리된 단어들을 하나의 단어로 인식하기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-heart",
   "metadata": {},
   "source": [
    "`tf.keras.preprocessing.text.Tokenizer` -> 정제된 데이터를 토큰화해 단어 사전을 만들어주고, 데이터를 숫자로 변환해준다.    \n",
    "* 벡터화: 문자를 숫자로 변환해주는 과정\n",
    "* 텐서: 숫자로 변환된 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-production",
   "metadata": {},
   "source": [
    "### 텐서(Tensor)\n",
    "데이터의 배열.    \n",
    "텐서의 rank는 몇차원 배열인가를 의미.    \n",
    "scalar의 집합 -> vector    \n",
    "vector의 집합 -> matrix    \n",
    "matrix의 집합 -> tensor    \n",
    "따라서 matrix는 3차원부터 시작하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-revision",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\n",
    "* num_words -> 기억할 단어 수\n",
    "* oov_token -> 지정하면 기억하고 있는 단어 외의 단어는 지정한 값으로 대체한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-niger",
   "metadata": {},
   "source": [
    "### pad sequences\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences    \n",
    "num_samples의 길이를 가진 list를 (num_samples, num_timesteps) 모양의 numpy array로 바꿔준다.     \n",
    "* num_timesteps : maxlen 인수이거나, list에서 가장 긴 길이    \n",
    "    num_timesteps보다 길이가 적은 시퀀스이면 값을 덧대어 길이를 맞춘다.    \n",
    "    num_timesteps보다 길이가 길면 주어진 길이에 맞게 시퀀스를 자른다.    \n",
    "* padding : 어느 위치에 값을 덧댈것인가?? pre(앞), post(뒤)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-video",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset    \n",
    "\n",
    "텐서로 생성된 데이터를 tf.data.Dataset객체를 생성하는 방법을 사용하면 속도가 빠르다.    \n",
    "-> '반복은 스트리밍 방식으로 수행되므로 전체 데이터셋을 메모리에 저장할 필요가 없습니다.'    \n",
    "이래서 빠르군.\n",
    "* 보통 아래와 같은 경우에 많이 사용한다\n",
    "    - 입력 데이터에서 소스 데이터 집합을 만듭니다.\n",
    "    - 데이터 집합 변환을 적용하여 데이터를 사전 처리합니다.\n",
    "    - 데이터셋 위에 반복하고 요소를 처리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-seller",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "단어를 벡터화하는 것이 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-bread",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Long Short-Term Memory    \n",
    "RNN의 특별한 한 종류    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
