{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parallel-seating",
   "metadata": {},
   "source": [
    "## 인공지능, 머신러닝, 딥러닝의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-ethnic",
   "metadata": {},
   "source": [
    "* 인공지능 : 기계를 지능적으로 만드는 것.\n",
    "* 머신러닝 : 제공된 데이터를 통해 스스로 학습하는 것. 데이터를 분석하고, 분석을 통해 학습하고, 학습한 내용을 기반을 판단이나 예측을 함.\n",
    "* 딥러닝 : 뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습하는 것.\n",
    "\n",
    "* 머신러닝과 딥러닝의 큰 차이 : 머신러닝은 학습 데이터를 수동으로 제공해야 하고, 딥러닝은 학습 데이터를 스스로 학습할 수 있다.\n",
    "\n",
    "https://wendys.tistory.com/136"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-filename",
   "metadata": {},
   "source": [
    "딥러닝의 목표는 데이터의 좋은 representation을 찾을 수 있는 machine을 만드는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-sunset",
   "metadata": {},
   "source": [
    "## 행동주의\n",
    "* 인간의 행동은 자극으로부터 직접적으로 만들어진다고 주장.\n",
    "* 인간의 지능과 내면은 후천적인 것이라고 주장.\n",
    "\n",
    "https://namu.wiki/w/%ED%96%89%EB%8F%99%EC%A3%BC%EC%9D%98%20%EC%8B%AC%EB%A6%AC%ED%95%99?from=%ED%96%89%EB%8F%99%EC%A3%BC%EC%9D%98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-france",
   "metadata": {},
   "source": [
    "### 조작적 조건화\n",
    "어떤 반응에 대해 선택적으로 보상함으로써 그 반응이 일어날 확률을 증가시키거나 감소시키는 방법    \n",
    "https://ko.wikipedia.org/wiki/%EC%A1%B0%EC%9E%91%EC%A0%81_%EC%A1%B0%EA%B1%B4%ED%99%94\n",
    "#### 스키너 상자\n",
    "조작적 조건형성은 스키너 상자를 통해 실험되고 증명되었다.    \n",
    "-> 사람들은 어떤 행동에 대해 보상이 주어지면 그 행동을 계속하고, 아무런 보상이 없거나 처벌을 받게 되면 그 행동을 중단 또는 하지 않으려 한다. 이러한 행동을 반복적으로 일어나게 하면, 점차 어떤 목표의 상태에 이르게 할 수 있다는 주장에 따라 순치이론이라고 부르기도 한다.    \n",
    "이러한 보상을 제공하는 것을 강화라고 하고, 이것은 강화학습의 근간이 된다.    \n",
    "http://www.edupolnews.com/news/articleView.html?idxno=11676\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-nickname",
   "metadata": {},
   "source": [
    "## 인지주의\n",
    "인간의 사고와 정보처리 과정을 과학적으로 탐구하는것.   \n",
    "인간이 받아들인 정보가 어떤 처리과정을 통해 가공되고 행동으로 표출되는지를 연구하는 것이다.    \n",
    "인간이 지식을 획득하는 방법, 획득한 지식을 구조화하여 축적하는 메커니즘을 주된 연구 대상으로 한다.   \n",
    "https://namu.wiki/w/%EC%9D%B8%EC%A7%80%EC%8B%AC%EB%A6%AC%ED%95%99?from=%EC%9D%B8%EC%A7%80%EC%A3%BC%EC%9D%98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-precipitation",
   "metadata": {},
   "source": [
    "## 연결주의\n",
    "연결주의의 지능체는 처음엔 백지상태이지만 경험을 함으로 학습해나간다.     |\n",
    "딥러닝은 연결주의에 기반한 이론이다.    \n",
    "https://ko.wikipedia.org/wiki/%EC%97%B0%EA%B2%B0%EC%A3%BC%EC%9D%98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-glenn",
   "metadata": {},
   "source": [
    "# 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-boundary",
   "metadata": {},
   "source": [
    "* Linear transformation : 특정 벡터를 다른 벡터로 바꾸는 것.\n",
    "* 왜 변환이라는 말을 쓸까?? 벡터를 동작이라는 개념으로 보면 방향이 움직이는 것이다.\n",
    "* Linear의 조건 : 원점은 0점을 지나고, 직선이어야 한다.    \n",
    "-> 어떻게 결과 벡터 좌표값이 나오게 할 까?? 결론은 두 개의 기저벡터가 어떻게 변하는지 파악하면 된다.\n",
    "-> 기저벡터의 위치만 알면 쉽게 계산할 수 있다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-background",
   "metadata": {},
   "source": [
    "#### 스칼라\n",
    "* 좌표계가 변환되어도 번하지 않는 것.\n",
    "* 전산학에서는 하나의 수를 가리키는 말로 쓰기도 한다.\n",
    "\n",
    "https://ko.wikipedia.org/wiki/%EC%8A%A4%EC%B9%BC%EB%9D%BC_(%EC%88%98%ED%95%99)    \n",
    "\n",
    "#### 벡터\n",
    "* 크기와 방향을 모두 포함하는 것.\n",
    "\n",
    "https://ko.wikipedia.org/wiki/%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%93%9C_%EB%B2%A1%ED%84%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-special",
   "metadata": {},
   "source": [
    "머신러닝과 딥러닝은 훈련 데이터에 딱 맞는 함수를 찾는 것이 아닌 근사한 함수를 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-greene",
   "metadata": {},
   "source": [
    "### 잘 근사하는 함수 찾기\n",
    "1. 모델을 어떤 함수로 표현할지 결정    \n",
    "    Inductive Bias : 최적의 함수가 특정한 함수 공간에 있다는 가설.    \n",
    "    ->이것이 중요한 이유는 일반적인 패턴을 반영해야 하기 때문이다. \n",
    "2. 함수 공간에서 최적의 함수를 찾는다. -> 모델 학습\n",
    "    딥러닝에서는 Gradient Descent를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-version",
   "metadata": {},
   "source": [
    "### 대표적인 딥러닝 모델\n",
    "1. 완전 연결 신경망\n",
    "2. 컨볼루션 신경망 -> 이미지 인식 분야에서 많이 쓰인다.\n",
    "3. 순환 신경망 -> 자연어 처리에서 많이 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-shirt",
   "metadata": {},
   "source": [
    "### 딥러닝의 강점\n",
    "1. feature 추출의 자동화 : 어려운 머신러닝 문제들에 대한 해결 성능을 극대화하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
